base_model: lapa-llm/lapa-12b-pt
tokenizer_config: lapa-llm/tokenizer


auto_resume_from_checkpoints: false

ddp_find_unused_parameters: true

remove_unused_columns: false

eot_tokens:
  - <end_of_turn>

shuffle_merged_datasets: true
shuffle_before_merging_datasets: true
datasets:
  - path: lapa-llm/hermes3-uk
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/hermes3-en-fixed
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value  
  - path: lapa-llm/antipropaganda-safe
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/antipropaganda-safe
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/antipropaganda-safe
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/antipropaganda-safe
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/wiki-instruction-dialogs
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/lapa-persona-qa
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/lapa-persona-qa
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/lapa-persona-qa
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/lapa-persona-qa
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/lapa-persona-qa
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/ua-lawyer
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/lang-uk-fiction-gec-dialogs
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/fiftyfive-best
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/openthoughts_no_think
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  #- path: lapa-llm/le-vision
  #  type: chat_template
  #  field_messages: conversations
  #  drop_system_message: true
  #  message_property_mappings:
  #    role: from
  #    content: value
  - path: lapa-llm/summaries # based on wiki-facts as summaries
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/wiki-facts-conversations
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value
  - path: lapa-llm/impossible-questions
    type: chat_template
    field_messages: conversations
    drop_system_message: true
    message_property_mappings:
      role: from
      content: value



ddp_timeout: 7200
dataset_processes: 16

dataset_prepared_path: last_run_prepared_instructions
# val_set_size: 0.01
output_dir: ./outputs/lapa-v0.1.2-matt-instructions-dft

sequence_len: 16384
sample_packing: true
pad_to_sequence_len: true
train_on_inputs: false

# The number of GPUs to shard the model parameters across (FSDP dimension).
dp_shard_size: 4

# The number of times to replicate the sharded model (DDP dimension).
dp_replicate_size: 3


plugins:
  - axolotl.integrations.liger.LigerPlugin
  - dft.dft_plugin.DFTPlugin
liger_rope: true
liger_rms_norm: true
liger_glu_activation: true
liger_layer_norm: true
liger_fused_linear_cross_entropy: true



wandb_project: gemma-3-12b-reasoning
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:

gradient_accumulation_steps: 10  # 3 nodes x 4 GPUs x 10 x 16_000 tokens in batch = 1.92M tokens per step
micro_batch_size: 1
num_epochs: 2
optimizer: adamw_torch_fused # muon #adamw_bnb_8bit
lr_scheduler: warmup_stable_decay
learning_rate: 2e-5
lr_scheduler_kwargs: {"num_decay_steps": 100}
max_grad_norm: 1.0
# weight_decay: 0.1
# 
# # adamw hyperparams
# adam_epsilon: 1e-10
# # adamw hyperparams
# adam_beta1: 0.9
# # adamw hyperparams
# adam_beta2: 0.98


bf16: auto
tf32: false 



fsdp:
  - full_shard
  - auto_wrap
fsdp_config:
  fsdp_version: 2
  fsdp_offload_params: false
  fsdp_cpu_ram_efficient_loading: false
  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
  fsdp_transformer_layer_cls_to_wrap: Gemma3DecoderLayer
  fsdp_state_dict_type: FULL_STATE_DICT
  fsdp_sharding_strategy: FULL_SHARD
  fsdp_reshard_after_forward: true
  fsdp_activation_checkpointing: true


logging_steps: 1
flash_attention: true 

warmup_steps: 100 

save_steps: 50
save_total_limit: 15



adam_epsilon: 1e-6 #bf16 edge-cases
# adamw hyperparams
adam_beta1: 0.9
# adamw hyperparams
# adam_beta2: 0.977543
adam_beta2: 0.98
weight_decay: 0.005
